# About This Book #

## License ##


The Little MongoDB စာအုပ်သည်  Attribution-NonCommercial 3.0 Unported လိုင်စင် အောက်တွင် တည်ရှိသဖြင့် 
**ထိုစာအုပ်အတွက် အခကြေးငွေ ပေးဆောင်ခြင်းမပြုရပါ။**

ထိုစာအုပ်ကို အခမဲ့ ကူးယူ၊ မျှဝေ၊ ပြင်ဆင်၊ ပြသနိုင်သော်လည်း စာရေးသူဖြစ်သည့် မိမိ Karl Seguin ကို ပြန်လည်ညွန်းဆိုရမည်ဖြစ်ပြီး စီးပွားဖြစ်သုံးစွဲခွင့်မပြုပါ။ 


ထိုလိုင်စင်၏ အရှည်ကောက်ကို အောက်ပါအတိုင်း ဖတ်ရှုနိုင်ပါသည်။

<http://creativecommons.org/licenses/by-nc/3.0/legalcode>

## စာရေးသူ အကြောင်း ##


Karl Seguin သည် နည်းပညာနှင့်ပတ်သတ်သော ဘာသာရပ်များတွင် အတွေ့အကြုံများစွာရှိသည့် developer တစ်ဦးဖြစ်သည်။ ၎င်းသည် .Net နှင့် Ruby ကျွမ်းကျင်သော developer တစ်ဦးဖြစ်သည့် အပြင် OSS Projects များကို တစ်စိတ်တစ်ပိုင်း contributor တစ်ဦးဖြစ်သည့် အပြင် နည်းပညာအကြောင်း ဟောပြောသူ နှင့် စာရေးသူ တစ်ဦးလည်း ဖြစ်သည်။ MongoDB နှင့်ပတ်သတ်၍လည်း C# ၏ MongoDB library ဖြစ်သော NoRM ၏ အဓိက contributor တစ်ဦးဖြစ်ပြီး [mongly](http://openmymind.net/mongly/)  နှင့် [Mongo Web Admin](https://github.com/karlseguin/Mongo-Web-Admin) တို့နှင့်ပတ်သတ်သော tutorial များကိုလည်းလည်း တွင်ရေးသားပါသေးသည်။ ၎င်း၏ game developer များအတွက် အခမဲ့ service ကို [mogade.com](http://mogade.com/) တွင်တွေ့နိုင်ပြီး MongoDB ကိုအသုံးပြုထားသည်။

Karl သည် [The Little Redis Book](http://openmymind.net/2012/1/23/The-Little-Redis-Book/) ကိုလည်းရေးသားခဲ့ပါသေးသည်။

သူ၏ blog ကို  <http://openmymind.net> တွင်တွေ့နိုင်ပြီး ၎င်း၏ twitter handle မှာ  [@karlseguin](http://twitter.com/karlseguin) ဖြစ်သည်။

## ကျေးဇူးတင်လွှာ ##

 သင်၏ မျက်လုံး စိတ်နှင့် ပြင်းထန်သော ဝါသနာများကို ငှားရမ်းမှုအတွက် [Perry Neal](http://twitter.com/perryneal) ကို အထူးပဲကျေးဇူးတင်ရှိရပါတယ်။ သင့်ရဲ့ကူညီမှုက တန်ဖိုးဖြတ်၍မရပါဘူး။ ကျေးဇူးပါ။
 

<http://github.com/karlseguin/the-little-mongodb-book>.

# နိဒါန်း #

 > အခန်းတွေ တိုတိုလေးဖြစ်တာ ကျွန်တော် အပြစ်မဟုတ်ပါဘူး။ MongoDB ကလေ့လာရ လွယ်လို့ပါ။

နည်းပညာတွေက အရွှေ့တွေက မြန်သည်ဟု ပြောကြသည်။ တနေ့တနေ့ နည်းပညာ အသစ်တွေနှင့် technique အသစ်တွေပေါ်လာသည်က မှန်သည်။ သို့သော်လည်း programmer တွေအသုံးပြုသော အခြေခံနည်းပညာများမှာမူ ဖြေးဖြေးချင်းစီသာ ပြောင်းလဲပါသည်။ တစ်နှစ်တစ်နှစ်တွင် အနည်းငယ်မျှသာ လေ့လာသောလည်း အလုပ်ဖြစ်နိုင်ပါသည်။ မြန်သည်ကတော့ နည်းပညာအဟောင်းများ နေရာတွင် အစားထိုးမည့် အသစ်များပါ။ တနေ့ထဲတွင် အချိန်ကြာမြင့်စွာတည်ဆောက်ထားသော နည်းပညာများ အသစ် deveoper များ၏ အပြောင်းအလဲကြောင့်ကို ကြောက်ရွံ့ရသည်။


နဂိုအသားကျနေသော relational database များမှ NoSQL နည်းပညာများသို့ ရုတ်တရွက်အရွေ့သည် ၎င်းကို ဖော်ပြနိုင်သော အကောင်းဆုံး ဥပမာဖြစ်သည်။ တနေ့တွင် web တစ်ခုလုံးသည် relational database များနှင့်
NoSQL solution ငါခုလောက်ဖြင့်သာ အသုံးပြုကြတော့မည် ဟုထင်ခဲ့ကြသည်။


၎င်း အပြောင်းအလဲများသည် နေ့ချင်းရက်ချင်းဖြစ်သော်လည်း တကယ်လက်တွေ့တွင် ထိုနည်းပညာများသည် တကယ့်လက်တွေ့တွင် သုံးနိုင်သည့် အခြေအနေရောက်အောင် နှစ်ပေါင်းများစွာကြာမြင့်ခဲ့သည်။ အစောပိုင်းတွင် developer အနည်းငယ်မျှသည် စိတ်အားထက်သန်မှုဖြင့် မောင်းနှင်ခဲ့ပြီး ပို၍ အဆင်ပြေလာသည်နှင့်အမျှ သင်ခန်းစာများရက နည်းပညာအသစ်၏ နေရာကိုရှာတွေ့ခဲ့ပြီး အခြားသူများမှာ တဖြည်းဖြည်း ၎င်းတို့အတွက် စမ်းကြည့်လာကြသည်။ ထပ်၍ ထုံးတမ်းစဉ်လာ storage solution များအနေဖြင့် အစားထိုး၍မရသော် နေရာများအတွက် NoSQL ၏ အနေအထားသည် မှန်သည်ဟုဆိုရမည်ဖြစ်ပြီး ထုံးတမ်းစဉ်လာ feature များထက် ဘယ်အချက်တွေ ပိုလာမလဲကိုသာ အဓိကပြောရမည်ဖြစ်သည်။ 


အပေါ်မှအတိုင်း ဆိုခဲ့ပြီးပါနောက် NoSQL ဆိုသည်မှာ ဘာလဲဆိုတာ ရှင်းပြရန်လိုမည်။ ၎င်းသည် ကွဲပြားသောသူများအတွက် ကွဲပြားသော အဓိပ္ပါယ်ဖွဲ့ဆိုချက်များ ဖြစ်သည်။ ကျွန်တော်အနေဖြင့်မူ data များ၏ သိမ်းဆည်းပုံနှင့် ပတ်သတ်၍ အဓိကကျသော နေရာတစ်ခုအဖြစ်ပါဝင်သော စနစ်တစ်ခုဟု အကြမ်းဖြင်းမှတ်ယူထားသည်။ တနည်းအားဖြင့် NoSQL သည် (ကျွန်တော်အတွက်) ခိုင်လုံသော စနစ်တစ်ခုသည် စက်တစ်လုံးထဲပေါ်တွင် မမူတည်နေသော ယုံကြည်ချက်ဖြစ်သည်။ 

ပုံမှန် relational database များ၏ ထုတ်လုပ်သူများသည် တောက်လျှောက် software တစ်ခုကို အားလုံးစုပြုံထားသော solution တစ်ခုအနေဖြင့် ပုံသွင်းရန်ကြိုးစားခဲ့သော်လည်း NoSQL အတွက်မူ သေးငယ်သော units များမှ တာဝန်အသီးသီးခွဲယူပြီး အကောင်းဆုံး tool များကို အသုံးပြု၍ တာဝန်တစ်ခုစီကို ထမ်းယူနိုင်ရန် ရည်ရွယ်သည်။
ထိုကြောင့် NoSQL stack တစ်ခုတွင် relational database နှင့်တွဲဖက်၍အသုံးပြုခြင်း ဆိုပါစို့  MySQL ကိုအသုံးပြုပေမယ့် Redis ကို စနစ်၏ အစိတ်အပိုင်းတချို့တွင် အသုံးပြုခြင်းနှင့် အကြီးအကျယ် data process ပြုလုပ်ပါက Haddop ကိုအသုံးပြုခြင်းကဲ့သို့ပင် ရိုးရှင်းစွာပြောပါက NoSQL သည် အခြားအစားထိုးတစ်ခုအတွက်ကို 
ဖွင့်လှစ်ထားခြင်း ၊ ရှိပြီးသား နှင့် pattern များနှင့် tool များကိုအသုံးပြု၍ data များကို ကွပ်ကဲခြင်းဖြစ်သည်။

MongoDB သည် ၎င်းတို့အားလုံးကို ဖြေရှင်းနိုင်မလား ဟု တွေးကောင်းတွေးလိမ့်မည်။ document-oriented database တစ်ခု အနေဖြင့် MongoDB သည် အထွေထွေဆန်သည် NoSQL solution တစ်ခုဖြစ်သည်။ ၎င်းကို relational datbase များ၏ အစားထိုး ဟုမြင်နိင်သည်။ relational database များကဲ့သို့ပင် တခြား NoSQL solution များနှင့် တွဲဖက်အသုံးပြုနိုင်သည်။ MongoDB တွင်အားသာချက်ကော အားနည်းချက်ပါရှိပြီး ၎င်းတို့ကို စာအုပ်၏ အခြားသောအပိုင်းများတွင် ဖော်ပြသွားမည်။


# အစပျိုး #


ဒီစာအုပ်၏ အများစုသည် MongoDB ၏ function များကို အာရုံစိုက်ထားမည်ဖြစ်၍ MongoDB Shell အပေါ်မှာ run မည်ဖြစ်သည်။ shell သည် administration ပြုလုပ်သည့် အပိုင်းများတွင် အသုးဝင်သည်ဖြစ်သော်လည်း သင့် Code မှာမူ MongoDB driver ကိုအသုံးပြုမည်ဖြစ်သည်။

ထိုကြောင့် MongoDB နှင့်ပတ်သတ်၍ ပထမဆုံးသိရန်မှာ ၎င်း၏ driver များဖြစ်သည်။ MongoDB တွင် Language များအတွက် [official drivers များစွာ](http://docs.mongodb.org/ecosystem/drivers/) ပါရှိသည်။ ၎င်း driver များကို အခြား သင်ရင်းနှီးပြီးသားဖြစ်သော် database driver များကဲ့သို့ မှတ်ယူနိုင်သည်။ ထိုအပြင် development community သည် language နှင့် framework အခြေပြု library များကိုတည်ဆောက်ထားသည်။ ဥပမာ
[fluent-mongo](https://github.com/craiggwilson/fluent-mongo) ကဲ့သို့သော C# library သည် LINQ အတွက်ပါ support ပေးပြီး [MongoMapper](https://github.com/jnunemaker/mongomapper) သည် Ruby အခြေပြု library ဖြစ်ပြီး ActiveRecord နှင့်နီးစပ်သည်။ သင့်အနေဖြင့် core MongoDB driver များကိုအခြေပြုပြီးရေးသားသည် ဖြစ်စေ အပေါ်တစ်ထပ်မှ library တစ်ခုခုအသုံးပြုသည်ဖြစ်စေ သင့်အပေါ်သာမူတည်သည်။ ထိုသို့ပြောရခြင်းမှာ MongoDB ကိုစတင်လေ့လာသူများသည် offical driver များနှင့် community library များကိုမြင်တွေ့ပြီး မျက်စိရှုပ်လေ့ရှိတက်သောကြောင့်ဖြစ်သည်။ ပထမတစ်ခုမှာ MongoDB ၏ communication နှင့် connectivity အပိုင်းကို အာရုံစိုက်ပြီး ဒုတိယတစ်ခုမှာ language နှင့် framework ဘက်မှ ချဉ်းကပ်ခြင်းဖြစ်သည်။

ဒီစာအုပ်ကိုဖတ်နေရင်း MongoDB နှင့် ကျွန်တော် ပြတဲ့ဟာတွေကို လိုက်စမ်းကြည့်ဖို့နှင့် မေးခွန်းတွေ ကိုယ်ဖာသာမေးကြည့်ဖို့ အားပေးပြါရစေ။

MongoDB တွင် Community version နှင့် Enterprise version ဟူ၍နှစ်မျိုးရှိသည်ဖြစ်ပြီး စတင်လေ့လာသူများအတွက် community version ကိုအသုံးပြုရမည်ဖြစ်သည်။ ထိုအပြင် MongoDB ကို Install ပြုလုပ်ရာတွင် Install ပြုလုပ်နည်းသုံးနည်းရှိပါသည်။ 

1. သက်ဆိုင်ရာ Package Manager များမှ install ပြုလုပ်ခြင်း
2. Installable Package များမှ click နှိပ်ပြီး install ပြုလုပ်ခြင်း (ဥပမာ .msi,.deb)
3. Binary folder ကို download ပြုလုပ်၍ ညွန်းဆိုအသုံးပြုခြင်း


၎င်းတို့အနက် မိမိတို့ အသုံးပြုသည် OS သည် windows မဟုတ်ပါက Package Manager မှ install ပြုလုပ်ရန်အကြံပြုလိုသည်။ တကယ်လက်တွေ့တွင် deploy ပြုလုပ်သော server များတွင် ထိုနည်းများကိုအသုံးပြုရမည် ဖြစ်သည်။ ထိုအပြင် upgrade ပြုလုပ်သည့်တာဝန်များကိုလည်း package manager များမှ တာဝန်ယူထားသဖြင့် ပိုမိုလွယ်ကူပါသည်။ ထိုနောက် မိမိတို့ အသုံးပြုမည့် Operation System ပေါ်မူတည်၍ အောက်ဖော်ပြပါလင့်များ အတွင်းသွား၍ install ပြုလုပ်ကြပါ။ [(Linux) ](https://docs.mongodb.com/manual/administration/install-on-linux/) [(Windows) ](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/) [(Mac)](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/)

`mongo` shell ကိုအသုံးပြုနိုင်ပါက အရင်ဆုံး `db.version()` ဟုရိုက်ထည့်ရင်းမိမိတို့အသုံးပြုသည့် database ၏ version ကိုကြည့်နိုင်ပါသည်။


# အခန်း(၁) အခြေခံ #

ပထမဆုံးခြေလှမ်းကိုတော့ MongoDB မည့်သိုအလုပ်လုပ်သနည်း ဆိုသည့် အခြေခံကိုပြောရင်းဖြင့် စပါမည်။ ၎င်းသည် MongoDB ကိုနားလည်ရာတွင် အဓိကအကျဆုံးအချက်ဖြစ်ပြီး MongoDB သည် မည်သို့သော အခြေအနေမျိုးနှင့် ကိုက်ညီသည် ဆိုသည့် မေးခွန်းများကို ဖြေရာတွင်လည်း အထောက်အကူပြုသည်။

ရှေးဦးစွာ အချက် ၆ ခုကို နားလည်ထားရန်လိုသည်။

1. MongoDB သည် အခြားသော database များကဲ့သို့ `database` ဟုသော concept အပေါ်တွင် အခြေခံသည်။

2. database တစ်ခုတွင် `collection` များပါရှိပြီး collection များသည် `table များနှင့်ဆင်၍ နှစ်ခုစလုံး အတူတူပဲဟု အစောပိုင်းမှတ်ယူနိုင်သည်။

3. Collection များသည် `document` များနှင့်ဖွဲ့စည်းထားပြီး ၎င်းတို့ကို `row` ကဲ့သို့ မှတ်ယူနိုင်သည်။

4. document တစ်ခုတွင် `field` များပါဝင်ပြီး ၎င်းတို့သည် `column` သဘောတရားနှင့် ဆင်တူသည်။

5. MongoDB တွင်ရှိသည့် `Index` များ၏ သဘောသဘာဝသည် RDBMS များနှင့်ဆင်သည်။

6. ၎င်းတွင်ပါရှိသော `Cursor` များသည် အခြား concept များနှင့်ကွဲပြားပြီး တခြားတရံချန်လှပ်ထားတက်သည်။ သို့သော် ၎င်းတို့ကို ဆွေးနွေးရန်ထိုက်တန်သည် ဟုမြင်ပါသည်။ အဓိကအချက်မှာ MongoDB မှ data ကိုလှမ်းယူလိုက်ပါက ပါသမျှ အကုန်ထုတ်ပေးသည်မဟုတ်ပဲ data များကို cursor ဟုခေါ်သည့် pointer တစ်ခုကို wrap လုပ်ပေးထားပြီ။ ၎င်းတို့ကို data တကယ်မဆွဲခင်ကတည်းက count ပြုလုပ်ရာတွင် ၎င်း ၊ ကျော်ရာတွင် ၎င်း အသုံးဝင်သည်။

အတိုချုပ်ပြောပါက MongoDB သည် `document` များပါဝင်သည့် `collection` များကိုစုစည်းထားသည့် `database` များနှင့်ဖွဲစည်းထားပြီး document တစ်ခုခြင်းစီတွင် `field` များပါဝင်သည်။ `collection` များကို 
ရှာဖွေရာတွင်နှင့် စီရာတွင် ပိုမိုမြန်ဆန်ကောင်းမွန်စေရန် `index` ပြုလုပ်နိုင်သည်။ နောက်ဆုံးတွင် mongodb မှ data များကို တိုက်ရိုက်ရသည်မဟုတ်ပဲ လိုအပ်မှ ဆွဲထုတ်ပေးသည့် `cursor` များမှ တဆင့်ရရှိသည်။

ဒါဆို ဘာလို့ စကားလုံးအသစ်တွေဖြစ်သည့် table အစား collection ၊ row အစား document ၊ column အစား field 
ဟု သုံးရသနည်း။ ပိုရှုပ်အောင်လား ? အမှန်မှာ ၎င်း concept များသည် Relational Database များမှ concept များနှင့် ဆင်သော်လည်း ထပ်တူမဟုတ်ပေ။ အဓိက ကွဲပြားချက်မှာ relational database များတွင် `column` များကို `table` အဆင့်တွင်တွင် သတ်မှတ်ပေးရပြီး document အထူးပြု database များတွင် `field` များကို `document` အဆင့်တွင် သတ်မှတ်ပေးရသည်။ ထို့ကြောင့် `collection` တစ်ခုအတွင်းရှိ `document` တစ်ခုချင်းစီသည် အမျိုးအစားမတူညီသော `field` များရှိနိုင်သည်။ ထိုကြောင့် `collection` သည် `table` နှင့်နှိုင်းစာလျင် ပေါ့ပေါ့လျော့လျော့ရှိပြီး `document` တွင် `row` ထက် အချက်အလက်ပိုများနိုင်သည်။

၎င်းကို နားလည်ရန် အရေးကြီးသော်လည် အခုလက်ရှိတွင် သိပ်မရှင်းသေးပါက ပြဿနာမရှိပါ။ ၎င်းကို နားလည်ရန် data အထည့်အသွင်း အကြိမ် အနည်းငယ် ပြုလုပ်ပါက နားလည်သွားပါလိမ့်မည်။ အထူးသတိပြုရန်မှာ collection များသည် မည်သည့် အချက်အလက်အမျိုးအစား ထည့်သွင်းထားသည်ကို restrict ပြုလုပ်မည် မဟုတ်ပါ။ (schema-less ဖြစ်သော်ကြောင့်) ၎င်း၏ အားသာချက်နှင့် အားနည်းချက်ကို နောက်အခန်းများတွင် ရှင်းပြသွားပါမည်။

စကြရအောင်။ သင့်အနေနဲ့ ဘာမှ မ run ရသေးပါက `mongod` ဆိုပြီး server ကိုစတင်လိုက်ပြီး mongo shell ထဲဝင်လိုက်ပါ။ ထို shell သည် Javascript ဖြင့် run ပြီး global command များဖြစ်သည့် `help` တို့ `exit` တို့ကိုလည်း အသုံးပြုနိုင်သည်။ လက်ရှိ database တစ်ခုလုံးစာ အရာများကို manageလုပ်ရန် `db` object အတွင်းရှိ command များပါရှိသည်။ (ဥပမာ `db.help()`၊ `db.stats()`) သို့မဟုတ် လက်ရှိ collection တစ်ခုစာ အရာများကို execute လုပ်ရန်မူ  `db.COLLECTION_NAME`  ဟု object များပါရှိသည်။ (ဥပမာ `db.unicorns.help()`၊ `db.unicorns.count()`)

`db.help()` ဟု ရိုက်ပြီးရှာကြည့်ပါ။ သင့်အနေဖြင့် `db` object အတွင်းတွင် execute ပြုလုပ်နိုင်သော commands list ကျလာပါလိမ့်မည်။

မှတ်သားရန် တစ်ခုမှာ Javascript Shell ဖြစ်တာကြောင့် method တစ်ခုကိုရိုက်ထည့်ရာတွင် parenthese ဖြစ်သည့် `()` ကို ဖြုတ်ပြီး ရိုက်ထည့်ကြည့်ပါက method ကိုခေါ်မည့် အစား method body ကိုတွေ့ရမည်ဖြစ်သည်။ ပြောရသည်မှာ သင့်အနေဖြင့် ပထမဆုံး response တစ်ခုမှာ `function (...){` ဟုပုံစံဖြင့် လာပါက အရမ်း မအံဩရန်ဖြစ်သည်။ ဥပမာ `db.help` ဟုရိုက်ထည့်ပါက `help` method ၏ internal implementation ကိုတွေ့ရမည်ဖြစ်သည်။ 

ပထမဦးစွာ `use` ဆိုသည့် global helper ကိုသုံး၍ database များကို switch ပြုလုပ်နိုင်သည်။ ထိုကြောင့် `use learn` ဆိုပြီးရိုက်လိုက်ပါ။ database မရှိသေးလည်း ကိစ္စမရှိပါ။ ပထမဆုံး collection ကိုတည်ဆောက်လိုက်ပါက `learn` database ပါ တခါတည်း ဆောက်သွားမည်ဖြစ်သည်။ အခု database ၏ အတွင်းထဲကိုရောက်သွားပြီ ဖြစ်၍ database command များဖြစ်သည့် `db.getCollectionNames()` ကိုသုံးနိုင်မည်ဖြစ်သည်။ အခုရိုက်ကြည့်ပါက array အလွတ် (`[ ]`) ကိုသာတွေ့မည်ဖြစ်သည်။ collection များမှာ schema မရှိသဖြင့် တကူးတက ဆောက်ရန်မလိုပေ။ document ကို insert လုပ်လိုက်ပါက collection ဖြစ်ပေါ်လာမည်ဖြစ်သည်။ ထိုသို့ပြုလုပ်ရန် `insert` command ကိုအသုံးပြုရမည်ဖြစ်ပြီး document ကို အောက်ပါအတိုင်း insert ပြုလုပ်လိုက်ပါ။


	db.unicorns.insert({name: 'Aurora',
		gender: 'f', weight: 450})


parameter အနေဖြင့် pass ပြီး `unicorns` collection ကို `insert` ပြုလုပ်မည်ဖြစ်သည်။ MongoDB ၏ အတွင်းပိုင်းတွင် BSON ဟုခေါ်သည့် Binary serialized JSON format ကိုအသုံးပြုပြီး ထိုကြောင့် အပြင်ပိုင်းတွင် JSON ကို အဓိကအသုံးပြုသည်ကို ပြော၍ရပြီး ကျွန်တော်တို့ လက်ရှိဥပမာတွင် မြင်တွေ့နိုင်သည်။ အကယ်၍ ဒီတစ်ခါ `db.getCollectionNames()` ရိုက်ကြည့်ပါက `unicorns` ကိုမြင်တွေ့ရမည်ဖြစ်သည်။

ယခု `unicorns` အတွင်းရှိ document များကို `find` ကိုအသုံးပြု၍ ရှာဖွေနိုင်ပါပြီ။

	db.unicorns.find()

သတိထားမိမည်မှာ မိမိတို့ထည့်ထားသည့် data များအပြင် `_id` ဟုသည့် field တစ်ခု အပိုပါနေသည်ကိုတွေ့ရမည်။ document တိုင်းတွင် သီးသန့် `_id` field ပါရှိသည်။ သင့်အနေဖြင့် ကိုယ်ဖာသာကိုယ် generate ပြုလုပ်နိုင်သလို
MongoDB မှ generate ပြုလုပ်ထားသည့် `ObjectId` ကိုလည်း အသုံးပြုနိုင်သည်။ အခြေအနေတော်တော်များများတွင် 
`ObjectId` ကိုအသုံးပြုဖို့များပါသည်။ default အနေဖြင့် `_id` သည် index ပြုလုပ်ထားသည်။ ၎င်းကို `getIndexes` command ကိုအသုံးပြု၍ သိရှိနိုင်သည်။

	db.unicorns.getIndexes()

index ၏ အမည်ကိုတွေ့ပါက database နှင့် collection နှင့် field တို့ပါ ထို index အတွင်းတွင် ပါရှိသည်ကို သတိထားမိမည်ဖြစ်သည်။

အခု ဆက်၍ schema-less collection အကြောင်း ဆွေးနွေးကြပါစို့။ `unicorns` အတွင်းသို့ လုံးဝမတူညီသည့် document တစ်ခုကို insert ပြုလုပ်ကြည့်ကြပါ။

	db.unicorns.insert({name: 'Leto',
		gender: 'm',
		home: 'Arrakeen',
		worm: false})


ထိုနောက် `find` ကိုအသုံးပြု၍ document များကို list လုပ်ပါ။ ထပ်၍လေ့လာပြီးပါက MongoDB ၏ စိတ်ဝင်စားစရာ သဘောတရားကို ဆွေးနွေးပါမယ်။ သို့သော် ယခု မြင်သာလာမည်က သမာရိုးကျ အသုံးအနှုန်းများသည် ၎င်းနှင့် မကိုက်ဆိုသည့် အချက်ကို။

## Mastering Selectors ##

အပေါ်မှ အချက် ခြောက်ချက်ကို စူးစမ်းနေရင်း အဆင့်မြင့်တန်း ကို ဆက်၍မလေ့လာမီ MongoDB ၏ လက်တွေ့ကျသည့် အချက် တနည်းအားဖြင့် query selectors များအကြောင်းကို နားလည်ထားရန်လိုသည်။  collection မှ ရှာသောခါ ၊ ရေတွက်သောအခါ ၊ ပြင်ဆင်သောအခါ နှင့် ဖျက်သောအခါများတွင် MongoDB ၏ query selector သည် SQL ၏ `where` statement များဖြင့် ခပ်ဆင်ဆင်ပင်ဖြစ်သည်။ JSON object သည် selector ဖြစ်ပြီး အရိုးရှင်းဆုံး ပုံစံသည် `{}` ဖြစ်ပြီး ၎င်းသည် document အကုန်လုံးဖြင့် match ဖြစ်မည်ဖြစ်သည်။ အကယ့်၍ female unicorns များကိုသာရှာလိုပါက `{gender:'f'}` ဟု အသုံးပြုနိုင်သည်။

selector များအကြောင်း ထဲထဲဝင်ဝင် မဆင်းခင် data များထည့်ပြီး စမ်းသပ်ကြည့်ကြရအောင်။ ပထမဆုံး unicorns တွင်ရှိပြီးသား collection ကို `db.unicorns.remove({})` ရိုက်ပြီး ရှင်းလင်းလိုက်ပါ။ ထိုနောက် အောက်ကအတိုင်း ( copy paste လုပ်ရန် အားပေးပါသည်) ရိုက်ထည်းလိုက်ပါ။ 

	db.unicorns.insert({name: 'Horny',
		dob: new Date(1992,2,13,7,47),
		loves: ['carrot','papaya'],
		weight: 600,
		gender: 'm',
		vampires: 63});
	db.unicorns.insert({name: 'Aurora',
		dob: new Date(1991, 0, 24, 13, 0),
		loves: ['carrot', 'grape'],
		weight: 450,
		gender: 'f',
		vampires: 43});
	db.unicorns.insert({name: 'Unicrom',
		dob: new Date(1973, 1, 9, 22, 10),
		loves: ['energon', 'redbull'],
		weight: 984,
		gender: 'm',
		vampires: 182});
	db.unicorns.insert({name: 'Roooooodles',
		dob: new Date(1979, 7, 18, 18, 44),
		loves: ['apple'],
		weight: 575,
		gender: 'm',
		vampires: 99});
	db.unicorns.insert({name: 'Solnara',
		dob: new Date(1985, 6, 4, 2, 1),
		loves:['apple', 'carrot',
			'chocolate'],
		weight:550,
		gender:'f',
		vampires:80});
	db.unicorns.insert({name:'Ayna',
		dob: new Date(1998, 2, 7, 8, 30),
		loves: ['strawberry', 'lemon'],
		weight: 733,
		gender: 'f',
		vampires: 40});
	db.unicorns.insert({name:'Kenny',
		dob: new Date(1997, 6, 1, 10, 42),
		loves: ['grape', 'lemon'],
		weight: 690,
		gender: 'm',
		vampires: 39});
	db.unicorns.insert({name: 'Raleigh',
		dob: new Date(2005, 4, 3, 0, 57),
		loves: ['apple', 'sugar'],
		weight: 421,
		gender: 'm',
		vampires: 2});
	db.unicorns.insert({name: 'Leia',
		dob: new Date(2001, 9, 8, 14, 53),
		loves: ['apple', 'watermelon'],
		weight: 601,
		gender: 'f',
		vampires: 33});
	db.unicorns.insert({name: 'Pilot',
		dob: new Date(1997, 2, 1, 5, 3),
		loves: ['apple', 'watermelon'],
		weight: 650,
		gender: 'm',
		vampires: 54});
	db.unicorns.insert({name: 'Nimue',
		dob: new Date(1999, 11, 20, 16, 15),
		loves: ['grape', 'carrot'],
		weight: 540,
		gender: 'f'});
	db.unicorns.insert({name: 'Dunx',
		dob: new Date(1976, 6, 18, 18, 18),
		loves: ['grape', 'watermelon'],
		weight: 704,
		gender: 'm',
		vampires: 165});


အခု data တွေရှိသွားပြီဆိုတော့ selector ကိုစမ်းလို့ရပါပြီ။  `{field: value}` ပုံစံဖြင့် ရှာရမည်ဖြစ်ပြီး `field` သည် `value` နှင့်ညီသည့်အရာများကိုရှာပေးမည်ဖြစ်သည်။  `{field1: value1, field2: value2}` ပုံစံသည် `and` statment နှင့်သွားတူမည်ဖြစ်သည်။ အထူး operator များဖြစ်သော `$lt`၊ `$lte`၊ `$gt`၊ `$gte` နှင့် `$ne` တို့သည်  ငယ်သော ၊ ငယ်သည်နှင့်တူသည်နှစ်ခုထဲမှ တစ်ခုကိုက်ညီသော ၊ ကြီးသော ၊ ကြီးသည်နှင့် တူသည် နှစ်ခုထဲမှ ကိုက်ညီသော နှင့် မတူညီသော အရာများကိုရှာဖွေရန်အသုံးပြုနိုင်သည်။ ဥပမာ unicorn များအနက်မှာ male ဖြစ်ပြီး weight ပေါင် ၇၀၀ ထက်ကျော်သည်ကိုရှာလိုပါက အောက်ပါအတိုင်း

	db.unicorns.find({gender: 'm',
		weight: {$gt: 700}})
	//or (not quite the same thing, but for
	//demonstration purposes)
	db.unicorns.find({gender: {$ne: 'f'},
		weight: {$gte: 701}})

`$exists` operator သည် field တစ်ခုရှိမရှိကို ဆန်းစစ်ရာတွင် အသုံးပြုနိုင်သည်။ ဥပမာ

	db.unicorns.find({
		vampires: {$exists: false}})

သည် document တစ်ခုသာပြန်လိမ့်မည်ဖြစ်သည်။ '$in' သည value များစွာပါဝင်သော array တစ်ခုထဲတွင် မိမိတို့အလို့ရှိသည့် value များပါသည့် array များနှင့် ကိုက်ညီခြင်းရှိမရှိ တိုက်စစ်ရာတွင် အသုံးပြုနိုင်သည်။

    db.unicorns.find({
    	loves: {$in:['apple','orange']}})

၎င်းသည် apple နှင့် orange ဖြစ်ဖြစ် ကြိုက်နှစ်သက်သော unicorn များ return ပြန်လိမ့်မည်။

field များကိုစစ်ရာတွင် AND အစား OR operator ကိုအသုံးပြုလိုပါက `$or` ကိုအသုံးပြုနိုင်ပြီး selector  array ကို pass ပြုလုပ်နိုင်သလို အောက်ပါအတိုင်းလည်း အသုံးပြုနိုင်သည်။

	db.unicorns.find({gender: 'f',
		$or: [{loves: 'apple'},
			  {weight: {$lt: 500}}]})

အပေါ်မှ အတိုင်းရေးပါက ပေါင် 500 အောက်ဖြစ်သည်ဖြစ်စေ ၊ apple ကိုနှစ်သက်သော female unicorn များကိုထုတ်ပေးမည်ဖြစ်သည်။ 

အပေါ်မှ ဥပမာနှစ်ခုတွင် သတိထားစရာအချက် ၂ ခုရှိသည်။ ပထမတစ်ခုမှာ `loves` ဆိုသော field သည် array ဖြစ်သည်။ MongoDB သည် array များကို first class object အနေဖြင့် အသိအမှတ်ပြုသည်။ ၎င်းသည်အလွန်အသုံးဝင်သော feature ဖြစ်ပြီး ရင်းနှီးသွားပါက ၎င်းမပါပဲ မသုံးတက်တော့ချေ။ ပို၍ စိတ်ဝင်စားစရာကောင်းသည်က array ၏ value ကို ရွေးချယ်ရာတွင် လွယ်ကူခြင်းဖြစ်ပြီး `{loves: 'watermelon'}` ဟုအသုံးပြုပါက `loves` ၏ တန်ဖိုး `watermelon` ဖြစ်သောအရာများပါလာမည်ဖြစ်သည်။

ယခု မြင်နေကြများအပြင် အခြား သုံးနိုင်သည့် operator များလည်းရှိပါသေးသည်။ ၎င်းတို့ကို MongoDB Manual ၏  [Query Selectors](http://docs.mongodb.org/manual/reference/operator/query/#query-selectors) section တွင်ဖတ်နိုင်သည်။ ယခုဖော်ပြခဲ့သော အရာများအခြေခံဖြစ်ပြီး ၎င်းတို့ကို အများစုအနေဖြင့် အသုံးပြုရမည်ဖြစ်သည်။

`find` command ကိုအသုံးပြု၍ selector များကိုအသုံးပြုသည်ကိုတွေ့ပြီးပြီဖြစ်သည်။ ၎င်းတို့ကိုလည်း ကျွန်တော်တိ့ တစ်ခေါက်အသုံးပြုဖူးသည့် `remove` command ဖြင့်လည်းတွဲဖက်အသုံးပြုနိုင်သလို `count` ဖြင့်လည်းသုံးနိုင်သည်။ ထိုနောက် `update` command ကို အချိန်တစ်ခုပေး၍ ရှင်းပြပါမည်။

MongoDB မှ `_id` field အတွက် generate ပြုလုပ်ပေးသော `ObjectId` ကိုအောက်ပါအတိုင်းမြင်တွေ့နိုင်သည်။

	db.unicorns.find(
		{_id: ObjectId("TheObjectId")})

## နောက်တစ်ခန်းမဖတ်ခင် ##

`update` command ကိုမကြည့်ရသေးသလို `find` ဖြင့်ပြုလုပ်၍ရသော အချို့သော မိုက်သည့် အရာများမစမ်းကြည့်ရသေးသော်လည်း MongoDB ကို install ပြုလုပ်ပြီး run ခြင်း၊ `insert` နှင့် `remove` ပြုလုပ်ခြင်းတို့ကို လုပ်ဆောင်ပြီးဖြစ်သည်။ ထိုနောက် `find` အကြောင်းနှင့် MongoDB မှ `selector` အကြောင်းကို မိတ်ဆက်ပေးခဲ့ပြီးဖြစ်သည်။ သင်ယုံချင်မှယုံမည်ဖြစ်သော်လည်း ယခုအခြေအနေလောက်ဖြင့် MongoDB နှင့်ပတ်သတ်သော အခြေခံတော်တော်များများကို သင်သိရှိပြီးဖြစ်သည်။ ထိုမျှပင် သင်ရလွယ်ကူသလို အသုံးပြုရလွယ်ကူသည်။ သို့သော် နောက်အဆင့်များမတိုင်ခင် local မှာပင် အကြိမ်ကြိမ်စမ်းသပ်ရန် အကြံပြုလိုသည်။ မတူညီသော documents များ insert ပြုလုပ်ခြင်း၊ collection အသစ်များဖန်တီးခြင်း၊ နှင့် selector များကိုရင်းနှီးအောင် လေ့လာထားသင့်သည်။ ကိုယ့်ဖာသာကိုယ် `find` ၊ `count` နှင့် `remove` များအသုံးပြုပြီး အကြိမ်ကြိမ်စမ်းသပ်ပါက တဖြည်းဖြည်းရင်းနှီးလာပြီး အသားကျလာပါလိမ့်မည်။

# Chapter 2 - Updating #
In chapter 1 we introduced three of the four CRUD (create, read, update and delete) operations. This chapter is dedicated to the one we skipped over: `update`. `Update` has a few surprising behaviors, which is why we dedicate a chapter to it.

## Update: Replace Versus $set ##
In its simplest form, `update` takes two parameters: the selector (where) to use and what updates to apply to fields. If Roooooodles had gained a bit of weight, you might expect that we should execute:

	db.unicorns.update({name: 'Roooooodles'},
		{weight: 590})

(If you've played with your `unicorns` collection and it doesn't have the original data anymore, go ahead and `remove` all documents and re-insert from the code in chapter 1.)

Now, if we look at the updated record:

	db.unicorns.find({name: 'Roooooodles'})

You should discover the first surprise of `update`. No document is found because the second parameter we supplied didn't have any update operators, and therefore it was used to **replace** the original document. In other words, the `update` found a document by `name` and replaced the entire document with the new document (the second parameter). There is no equivalent functionality to this in SQL's `update` command. In some situations, this is ideal and can be leveraged for some truly dynamic updates. However, when you want to change the value of one, or a few fields, you must use MongoDB's `$set` operator. Go ahead and run this update to reset the lost fields:

	db.unicorns.update({weight: 590}, {$set: {
		name: 'Roooooodles',
		dob: new Date(1979, 7, 18, 18, 44),
		loves: ['apple'],
		gender: 'm',
		vampires: 99}})

This won't overwrite the new `weight` since we didn't specify it. Now if we execute:

	db.unicorns.find({name: 'Roooooodles'})

We get the expected result. Therefore, the correct way to have updated the weight in the first place is:

	db.unicorns.update({name: 'Roooooodles'},
		{$set: {weight: 590}})

## Update Operators ##
In addition to `$set`, we can leverage other operators to do some nifty things. All update operators work on fields - so your entire document won't be wiped out. For example, the `$inc` operator is used to increment a field by a certain positive or negative amount. If Pilot was incorrectly awarded a couple vampire kills, we could correct the mistake by executing:

	db.unicorns.update({name: 'Pilot'},
		{$inc: {vampires: -2}})

If Aurora suddenly developed a sweet tooth, we could add a value to her `loves` field via the `$push` operator:

	db.unicorns.update({name: 'Aurora'},
		{$push: {loves: 'sugar'}})

The [Update Operators](http://docs.mongodb.org/manual/reference/operator/update/#update-operators) section of the MongoDB manual has more information on the other available update operators.

## Upserts ##
One of the more pleasant surprises of using `update` is that it fully supports `upserts`. An `upsert` updates the document if found or inserts it if not. Upserts are handy to have in certain situations and when you run into one, you'll know it. To enable upserting we pass a third parameter to update `{upsert:true}`.

A mundane example is a hit counter for a website. If we wanted to keep an aggregate count in real time, we'd have to see if the record already existed for the page, and based on that decide to run an update or insert. With the upsert option omitted (or set to false), executing the following won't do anything:

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}});
	db.hits.find();

However, if we add the upsert option, the results are quite different:

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}}, {upsert:true});
	db.hits.find();

Since no documents exists with a field `page` equal to `unicorns`, a new document is inserted. If we execute it a second time, the existing document is updated and `hits` is incremented to 2.

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}}, {upsert:true});
	db.hits.find();

## Multiple Updates ##
The final surprise `update` has to offer is that, by default, it'll update a single document. So far, for the examples we've looked at, this might seem logical. However, if you executed something like:

	db.unicorns.update({},
		{$set: {vaccinated: true }});
	db.unicorns.find({vaccinated: true});

You might expect to find all of your precious unicorns to be vaccinated. To get the behavior you desire, the `multi` option must be set to true:

	db.unicorns.update({},
		{$set: {vaccinated: true }},
		{multi:true});
	db.unicorns.find({vaccinated: true});

## In This Chapter ##
This chapter concluded our introduction to the basic CRUD operations available against a collection. We looked at `update` in detail and observed three interesting behaviors. First, if you pass it a document without update operators, MongoDB's `update` will replace the existing document. Because of this, normally you will use the `$set` operator (or one of the many other available operators that modify the document). Secondly, `update` supports an intuitive `upsert` option which is particularly useful when you don't know if the document already exists. Finally, by default, `update` updates only the first matching document, so use the `multi` option when you want to update all matching documents.

# Chapter 3 - Mastering Find #
Chapter 1 provided a superficial look at the `find` command. There's more to `find` than understanding `selectors` though. We already mentioned that the result from `find` is a `cursor`. We'll now look at exactly what this means in more detail.

## Field Selection ##
Before we jump into `cursors`, you should know that `find` takes a second optional parameter called "projection". This parameter is the list of fields we want to retrieve or exclude. For example, we can get all of the unicorns' names without getting back other fields by executing:

	db.unicorns.find({}, {name: 1});

By default, the `_id` field is always returned. We can explicitly exclude it by specifying `{name:1, _id: 0}`.

Aside from the `_id` field, you cannot mix and match inclusion and exclusion. If you think about it, that actually makes sense. You either want to select or exclude one or more fields explicitly.

## Ordering ##
A few times now I've mentioned that `find` returns a cursor whose execution is delayed until needed. However, what you've no doubt observed from the shell is that `find` executes immediately. This is a behavior of the shell only. We can observe the true behavior of `cursors` by looking at one of the methods we can chain to `find`. The first that we'll look at is `sort`. We specify the fields we want to sort on as a JSON document, using 1 for ascending and -1 for descending. For example:

	//heaviest unicorns first
	db.unicorns.find().sort({weight: -1})

	//by unicorn name then vampire kills:
	db.unicorns.find().sort({name: 1,
		vampires: -1})

As with a relational database, MongoDB can use an index for sorting. We'll look at indexes in more detail later on. However, you should know that MongoDB limits the size of your sort without an index. That is, if you try to sort a very large result set which can't use an index, you'll get an error. Some people see this as a limitation. In truth, I wish more databases had the capability to refuse to run unoptimized queries. (I won't turn every MongoDB drawback into a positive, but I've seen enough poorly optimized databases that I sincerely wish they had a strict-mode.)

## Paging ##
Paging results can be accomplished via the `limit` and `skip` cursor methods. To get the second and third heaviest unicorn, we could do:

	db.unicorns.find()
		.sort({weight: -1})
		.limit(2)
		.skip(1)

Using `limit` in conjunction with `sort`, can be a way to avoid running into problems when sorting on non-indexed fields.

## Count ##
The shell makes it possible to execute a `count` directly on a collection, such as:

	db.unicorns.count({vampires: {$gt: 50}})

In reality, `count` is actually a `cursor` method, the shell simply provides a shortcut. Drivers which don't provide such a shortcut need to be executed like this (which will also work in the shell):

	db.unicorns.find({vampires: {$gt: 50}})
		.count()

## In This Chapter ##
Using `find` and `cursors` is a straightforward proposition. There are a few additional commands that we'll either cover in later chapters or which only serve edge cases, but, by now, you should be getting pretty comfortable working in the mongo shell and understanding the fundamentals of MongoDB.

# Chapter 4 - Data Modeling #
Let's shift gears and have a more abstract conversation about MongoDB. Explaining a few new terms and some new syntax is a trivial task. Having a conversation about modeling with a new paradigm isn't as easy. The truth is that most of us are still finding out what works and what doesn't when it comes to modeling with these new technologies. It's a conversation we can start having, but ultimately you'll have to practice and learn on real code.

Out of all NoSQL databases, document-oriented databases are probably the most similar to relational databases - at least when it comes to modeling. However, the differences that exist are important.

## No Joins ##
The first and most fundamental difference that you'll need to get comfortable with is MongoDB's lack of joins. I don't know the specific reason why some type of join syntax isn't supported in MongoDB, but I do know that joins are generally seen as non-scalable. That is, once you start to split your data horizontally, you end up performing your joins on the client (the application server) anyway. Regardless of the reasons, the fact remains that data *is* relational, and MongoDB doesn't support joins.

Without knowing anything else, to live in a join-less world, we have to do joins ourselves within our application's code. Essentially we need to issue a second query to `find` the relevant data in a second collection. Setting our data up isn't any different than declaring a foreign key in a relational database. Let's give a little less focus to our beautiful `unicorns` and a bit more time to our `employees`. The first thing we'll do is create an employee (I'm providing an explicit `_id` so that we can build coherent examples)

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d730"),
		name: 'Leto'})

Now let's add a couple employees and set their manager as `Leto`:

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d731"),
		name: 'Duncan',
		manager: ObjectId(
		"4d85c7039ab0fd70a117d730")});
	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d732"),
		name: 'Moneo',
		manager: ObjectId(
		"4d85c7039ab0fd70a117d730")});


(It's worth repeating that the `_id` can be any unique value. Since you'd likely use an `ObjectId` in real life, we'll use them here as well.)

Of course, to find all of Leto's employees, one simply executes:

	db.employees.find({manager: ObjectId(
		"4d85c7039ab0fd70a117d730")})

There's nothing magical here. In the worst cases, most of the time, the lack of join will merely require an extra query (likely indexed).

## Arrays and Embedded Documents ##
Just because MongoDB doesn't have joins doesn't mean it doesn't have a few tricks up its sleeve. Remember when we saw that MongoDB supports arrays as first class objects of a document? It turns out that this is incredibly handy when dealing with many-to-one or many-to-many relationships. As a simple example, if an employee could have two managers, we could simply store these in an array:

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d733"),
		name: 'Siona',
		manager: [ObjectId(
		"4d85c7039ab0fd70a117d730"),
		ObjectId(
		"4d85c7039ab0fd70a117d732")] })

Of particular interest is that, for some documents, `manager` can be a scalar value, while for others it can be an array. Our original `find` query will work for both:

	db.employees.find({manager: ObjectId(
		"4d85c7039ab0fd70a117d730")})

You'll quickly find that arrays of values are much more convenient to deal with than many-to-many join-tables.

Besides arrays, MongoDB also supports embedded documents. Go ahead and try inserting a document with a nested document, such as:

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d734"),
		name: 'Ghanima',
		family: {mother: 'Chani',
			father: 'Paul',
			brother: ObjectId(
		"4d85c7039ab0fd70a117d730")}})

In case you are wondering, embedded documents can be queried using a dot-notation:

	db.employees.find({
		'family.mother': 'Chani'})

We'll briefly talk about where embedded documents fit and how you should use them.

Combining the two concepts, we can even embed arrays of documents:

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d735"),
		name: 'Chani',
		family: [ {relation:'mother',name: 'Chani'},
			{relation:'father',name: 'Paul'},
			{relation:'brother', name: 'Duncan'}]})


## Denormalization ##
Yet another alternative to using joins is to denormalize your data. Historically, denormalization was reserved for performance-sensitive code, or when data should be snapshotted (like in an audit log). However, with the ever-growing popularity of NoSQL, many of which don't have joins, denormalization as part of normal modeling is becoming increasingly common. This doesn't mean you should duplicate every piece of information in every document. However, rather than letting fear of duplicate data drive your design decisions, consider modeling your data based on what information belongs to what document.

For example, say you are writing a forum application. The traditional way to associate a specific `user` with a `post` is via a `userid` column within `posts`. With such a model, you can't display `posts` without retrieving (joining to) `users`. A possible alternative is simply to store the `name` as well as the `userid` with each `post`. You could even do so with an embedded document, like `user: {id: ObjectId('Something'), name: 'Leto'}`. Yes, if you let users change their name, you may have to update each document (which is one multi-update).

Adjusting to this kind of approach won't come easy to some. In a lot of cases it won't even make sense to do this. Don't be afraid to experiment with this approach though. It's not only suitable in some circumstances, but it can also be the best way to do it.

## Which Should You Choose? ##
Arrays of ids can be a useful strategy when dealing with one-to-many or many-to-many scenarios. But more commonly, new developers are left deciding between using embedded documents versus doing "manual" referencing.

First, you should know that an individual document is currently limited to 16 megabytes in size. Knowing that documents have a size limit, though quite generous, gives you some idea of how they are intended to be used. At this point, it seems like most developers lean heavily on manual references for most of their relationships. Embedded documents are frequently leveraged, but mostly for smaller pieces of data which we want to always pull with the parent document. A real world example may be to store an `addresses` documents with each user, something like:

	db.users.insert({name: 'leto',
		email: 'leto@dune.gov',
		addresses: [{street: "229 W. 43rd St",
		            city: "New York", state:"NY",zip:"10036"},
		           {street: "555 University",
		            city: "Palo Alto", state:"CA",zip:"94107"}]})

This doesn't mean you should underestimate the power of embedded documents or write them off as something of minor utility. Having your data model map directly to your objects makes things a lot simpler and often removes the need to join. This is especially true when you consider that MongoDB lets you query and index fields of an embedded documents and arrays.

## Few or Many Collections ##
Given that collections don't enforce any schema, it's entirely possible to build a system using a single collection with a mishmash of documents but it would be a very bad idea.  Most MongoDB systems are laid out somewhat similarly to what you'd find in a relational system, though with fewer collections. In other words, if it would be a table in a relational database, there's a chance it'll be a collection in MongoDB (many-to-many join tables being an important exception as well as tables that exist only to enable one to many relationships with simple entities).

The conversation gets even more interesting when you consider embedded documents. The example that frequently comes up is a blog. Should you have a `posts` collection and a `comments` collection, or should each `post` have an array of `comments` embedded within it? Setting aside the 16MB document size limit for the time being (all of *Hamlet* is less than 200KB, so just how popular is your blog?), most developers should prefer to separate things out. It's simply cleaner, gives you better performance and more explicit.  MongoDB's flexible schema allows you to combine the two approaches by keeping comments in their own collection but embedding a few comments (maybe the first few) in the blog post to be able to display them with the post.  This follows the principle of keeping together data that you want to get back in one query.

There's no hard rule (well, aside from 16MB). Play with different approaches and you'll get a sense of what does and does not feel right.

## In This Chapter ##
Our goal in this chapter was to provide some helpful guidelines for modeling your data in MongoDB, a starting point, if you will. Modeling in a document-oriented system is different, but not too different, than in a relational world. You have more flexibility and one constraint, but for a new system, things tend to fit quite nicely. The only way you can go wrong is by not trying.

# Chapter 5 - When To Use MongoDB #
By now you should have a feel for where and how MongoDB might fit into your existing system. There are enough new and competing storage technologies that it's easy to get overwhelmed by all of the choices.

For me, the most important lesson, which has nothing to do with MongoDB, is that you no longer have to rely on a single solution for dealing with your data. No doubt, a single solution has obvious advantages, and for a lot projects - possibly even most - a single solution is the sensible approach. The idea isn't that you *must* use different technologies, but rather that you *can*. Only you know whether the benefits of introducing a new solution outweigh the costs.

With that said, I'm hopeful that what you've seen so far has made you see MongoDB as a general solution. It's been mentioned a couple times that document-oriented databases share a lot in common with relational databases. Therefore, rather than tiptoeing around it, let's simply state that MongoDB should be seen as a direct alternative to relational databases. Where one might see Lucene as enhancing a relational database with full text indexing, or Redis as a persistent key-value store, MongoDB is a central repository for your data.

Notice that I didn't call MongoDB a *replacement* for relational databases, but rather an *alternative*. It's a tool that can do what a lot of other tools can do. Some of it MongoDB does better, some of it MongoDB does worse. Let's dissect things a little further.

## Flexible Schema ##
An oft-touted benefit of document-oriented database is that they don't enforce a fixed schema. This makes them much more flexible than traditional database tables. I agree that flexible schema is a nice feature, but not for the main reason most people mention.

People talk about schema-less as though you'll suddenly start storing a crazy mishmash of data. There are domains and data sets which can really be a pain to model using relational databases, but I see those as edge cases. Schema-less is cool, but most of your data is going to be highly structured. It's true that having an occasional mismatch can be handy, especially when you introduce new features, but in reality it's nothing a nullable column probably wouldn't solve just as well.

For me, the real benefit of dynamic schema is the lack of setup and the reduced friction with OOP. This is particularly true when you're working with a static language. I've worked with MongoDB in both C# and Ruby, and the difference is striking. Ruby's dynamism and its popular ActiveRecord implementations already reduce much of the object-relational impedance mismatch. That isn't to say MongoDB isn't a good match for Ruby, it really is. Rather, I think most Ruby developers would see MongoDB as an incremental improvement, whereas C# or Java developers would see a fundamental shift in how they interact with their data.

Think about it from the perspective of a driver developer. You want to save an object? Serialize it to JSON (technically BSON, but close enough) and send it to MongoDB. There is no property mapping or type mapping. This straightforwardness definitely flows to you, the end developer.

## Writes ##
One area where MongoDB can fit a specialized role is in logging. There are two aspects of MongoDB which make writes quite fast. First, you have an option to send a write command and have it return immediately without waiting for the write to be acknowledged. Secondly, you can control the write behavior with respect to data durability. These settings, in addition to specifying how many servers should get your data before being considered successful, are configurable per-write, giving you a great level of control over write performance and data durability.

In addition to these performance factors, log data is one of those data sets which can often take advantage of schema-less collections. Finally, MongoDB has something called a [capped collection](http://docs.mongodb.org/manual/core/capped-collections/). So far, all of the implicitly created collections we've created are just normal collections. We can create a capped collection by using the `db.createCollection` command and flagging it as capped:

	//limit our capped collection to 1 megabyte
	db.createCollection('logs', {capped: true,
		size: 1048576})

When our capped collection reaches its 1MB limit, old documents are automatically purged. A limit on the number of documents, rather than the size, can be set using `max`. Capped collections have some interesting properties. For example, you can update a document but it can't change in size. The insertion order is preserved, so you don't need to add an extra index to get proper time-based sorting.  You can "tail" a capped collection the way you tail a file in Unix via `tail -f <filename>` which allows you to get new data as it arrives, without having to re-query it.

If you want to "expire" your data based on time rather than overall collection size, you can use [TTL Indexes](http://docs.mongodb.org/manual/tutorial/expire-data/) where TTL stands for "time-to-live".

## Durability ##
Prior to version 1.8, MongoDB did not have single-server durability. That is, a server crash would likely result in lost or corrupt data. The solution had always been to run MongoDB in a multi-server setup (MongoDB supports replication). Journaling was one of the major features added in 1.8. Since version 2.0 MongoDB enables journaling by default, which allows fast recovery of the server in case of a crash or abrupt power loss.

Durability is only mentioned here because a lot has been made around MongoDB's past lack of single-server durability. This'll likely show up in Google searches for some time to come. Information you find about journaling being a missing feature is simply out of date.

## Full Text Search ##
True full text search capability is a recent addition to MongoDB.  It supports fifteen languages with stemming and stop words. With MongoDB's support for arrays and full text search you will only need to look to other solutions if you need a more powerful and full-featured full text search engine.  

## Transactions ##
MongoDB doesn't have transactions. It has two alternatives, one which is great but with limited use, and the other that is cumbersome but flexible.

The first is its many atomic update operations. These are great, so long as they actually address your problem. We already saw some of the simpler ones, like `$inc` and `$set`. There are also commands like `findAndModify` which can update or delete a document and return it atomically.

The second, when atomic operations aren't enough, is to fall back to a two-phase commit. A two-phase commit is to transactions what manual dereferencing is to joins. It's a storage-agnostic solution that you do in code. Two-phase commits are actually quite popular in the relational world as a way to implement transactions across multiple databases. The MongoDB website [has an example](http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/) illustrating the most typical example (a transfer of funds). The general idea is that you store the state of the transaction within the actual document being updated atomically and go through the init-pending-commit/rollback steps manually.

MongoDB's support for nested documents and flexible schema design makes two-phase commits slightly less painful, but it still isn't a great process, especially when you are just getting started with it.

## Data Processing ##
Before version 2.2 MongoDB relied on MapReduce for most data processing jobs. As of 2.2 it has added a powerful feature called  [aggregation framework or pipeline](http://docs.mongodb.org/manual/core/aggregation-pipeline/), so you'll only need to use MapReduce in rare cases where you need complex functions for aggregations that are not yet supported in the pipeline. In the next chapter we'll look at Aggregation Pipeline and MapReduce in detail. For now you can think of them as feature-rich and different ways to `group by` (which is an understatement).  For parallel processing of very large data, you may need to rely on something else, such as Hadoop. Thankfully, since the two systems really do complement each other, there's a [MongoDB connector for Hadoop](http://docs.mongodb.org/ecosystem/tools/hadoop/).

Of course, parallelizing data processing isn't something relational databases excel at either. There are plans for future versions of MongoDB to be better at handling very large sets of data.

## Geospatial ##
A particularly powerful feature of MongoDB is its support for [geospatial indexes](http://docs.mongodb.org/manual/applications/geospatial-indexes/). This allows you to store either geoJSON or x and y coordinates within documents and then find documents that are `$near` a set of coordinates or `$within` a box or circle. This is a feature best explained via some visual aids, so I invite you to try the [5 minute geospatial interactive tutorial](http://mongly.openmymind.net/geo/index), if you want to learn more.

## Tools and Maturity ##
You probably already know the answer to this, but MongoDB is obviously younger than most relational database systems. This is absolutely something you should consider, though how much it matters depends on what you are doing and how you are doing it. Nevertheless, an honest assessment simply can't ignore the fact that MongoDB is younger and the available tooling around isn't great (although the tooling around a lot of very mature relational databases is pretty horrible too!). As an example, the lack of support for base-10 floating point numbers will obviously be a concern (though not necessarily a show-stopper) for systems dealing with money.

On the positive side, drivers exist for a great many languages, the protocol is modern and simple, and development is happening at blinding speeds. MongoDB is in production at enough companies that concerns about maturity, while valid, are quickly becoming a thing of the past.

## In This Chapter ##
The message from this chapter is that MongoDB, in most cases, can replace a relational database. It's much simpler and straightforward; it's faster and generally imposes fewer restrictions on application developers. The lack of transactions can be a legitimate and serious concern. However, when people ask *where does MongoDB sit with respect to the new data storage landscape?* the answer is simple: **right in the middle**.

# Chapter 6 - Aggregating Data #

## Aggregation Pipeline ##
Aggregation pipeline gives you a way to transform and combine documents in your collection.  You do it by passing the documents through a pipeline that's somewhat analogous to the Unix "pipe" where you send output from one command to another to a third, etc.

The simplest aggregation you are probably already familiar with is the SQL `group by` expression.  We already saw the simple `count()`  method, but what if we want to see how many unicorns are male and how many are female?  

	db.unicorns.aggregate([{$group:{_id:'$gender',
		total: {$sum:1}}}])

In the shell we have the `aggregate` helper which takes an array of pipeline operators.  For a simple count grouped by something, we only need one such operator and it's called `$group`.   This is the exact analog of `GROUP BY` in SQL where we create a new document with `_id` field indicating what field we are grouping by (here it's `gender`) and other fields usually getting assigned results of some aggregation, in this case we `$sum` 1 for each document that matches a particular gender.  You probably noticed that the `_id` field was assigned `'$gender'` and not `'gender'` - the `'$'` before a field name indicates that the value of this field from incoming document will be substituted.

What are some of the other pipeline operators that we can use?  The most common one to use before (and frequently after) `$group` would be `$match` - this is exactly like the `find` method and it allows us to aggregate only a matching subset of our documents, or to exclude some documents from our result.

	db.unicorns.aggregate([{$match: {weight:{$lt:600}}},
		{$group: {_id:'$gender',  total:{$sum:1},
		  avgVamp:{$avg:'$vampires'}}},
		{$sort:{avgVamp:-1}} ])

Here we introduced another pipeline operator `$sort` which does exactly what you would expect, along with it we also get `$skip` and `$limit`.  We also used a `$group` operator `$avg`.

MongoDB arrays are powerful and they don't stop us from being able to aggregate on values that are stored inside of them.  We do need to be able to "flatten" them to properly count everything:

	db.unicorns.aggregate([{$unwind:'$loves'},
     	{$group: {_id:'$loves',  total:{$sum:1},
	 	unicorns:{$addToSet:'$name'}}},
	  	{$sort:{total:-1}},
	  	{$limit:1} ])

Here we will find out which food item is loved by the most unicorns and we will also get the list of names of all the unicorns that love it.  `$sort` and `$limit` in combination allow you to get answers to "top N" types of questions.

There is another powerful pipeline operator called [`$project`](http://docs.mongodb.org/manual/reference/operator/aggregation/project/#pipe._S_project) (analogous to the projection we can specify to `find`) which allows you not just to include certain fields, but to create or calculate new fields based on values in existing fields.  For example, you can use math operators to add together values of several fields before finding out the average, or you can use string operators to create a new field that's a concatenation of some existing fields.

This just barely scratches the surface of what you can do with aggregations.  In 2.6 aggregation got more powerful as the aggregate command returns either a cursor to the result set (which you already know how to work with from Chapter 1) or it can write your results into a new collection using the `$out` pipeline operator.  You can see a lot more examples as well as all of the supported pipeline and expression operators in the [MongoDB manual](http://docs.mongodb.org/manual/core/aggregation-pipeline/).

## MapReduce ##
MapReduce is a two-step approach to data processing. First you map, and then you reduce. The mapping step transforms the inputted documents and emits a key=>value pair (the key and/or value can be complex). Then, key/value pairs are grouped by key, such that values for the same key end up in an array. The reduce gets a key and the array of values emitted for that key, and produces the final result.  The map and reduce functions are written in JavaScript.

With MongoDB we use the `mapReduce` command on a collection. `mapReduce` takes a map function, a reduce function and an output directive. In our shell we can create and pass a JavaScript function. From most libraries you supply a string of your functions (which is a bit ugly). The third parameter sets additional options, for example we could filter, sort and limit the documents that we want analyzed. We can also supply a `finalize` method to be applied to the results after the `reduce` step.

You probably won't need to use MapReduce for most of your aggregations, but if you do, you can read more about it [on my blog](http://openmymind.net/2011/1/20/Understanding-Map-Reduce/) and in [MongoDB manual](http://docs.mongodb.org/manual/core/map-reduce/).

## In This Chapter ##
In this chapter we covered MongoDB's [aggregation capabilities](http://docs.mongodb.org/manual/aggregation/).  Aggregation Pipeline is relatively simple to write once you understand how it's structured and it's a powerful way to group data. MapReduce is more complicated to understand, but its capabilities can be as boundless as any code you can write in JavaScript.

# Chapter 7 - Performance and Tools #
In this last chapter, we look at a few performance topics as well as some of the tools available to MongoDB developers. We won't dive deeply into either topic, but we will examine the most important aspects of each.

## Indexes ##
At the very beginning we saw the `getIndexes` command which shows information on all the indexes in a collection. Indexes in MongoDB work a lot like indexes in a relational database: they help improve query and sorting performance. Indexes are created via `ensureIndex`:

	// where "name" is the field name
	db.unicorns.ensureIndex({name: 1});

And dropped via `dropIndex`:

	db.unicorns.dropIndex({name: 1});

A unique index can be created by supplying a second parameter and setting `unique` to `true`:

	db.unicorns.ensureIndex({name: 1},
		{unique: true});

Indexes can be created on embedded fields (again, using the dot-notation) and on array fields. We can also create compound indexes:

	db.unicorns.ensureIndex({name: 1,
		vampires: -1});

The direction of your index (1 for ascending, -1 for descending) doesn't matter for a single key index, but it can make a difference for compound indexes when you are sorting on more than one indexed field.

The [indexes page](http://docs.mongodb.org/manual/indexes/) has additional information on indexes.

## Explain ##
To see whether or not your queries are using an index, you can use the `explain` method on a cursor:

	db.unicorns.find().explain()

The output tells us that a `BasicCursor` was used (which means non-indexed), that 12 objects were scanned, how long it took, what index, if any, was used as well as a few other pieces of useful information.

If we change our query to use an index, we'll see that a `BtreeCursor` was used, as well as the index used to fulfill the request:

	db.unicorns.find({name: 'Pilot'}).explain()

## Replication ##
MongoDB replication works in some ways similarly to how relational database replication works. All production deployments should be replica sets, which consist of ideally three or more servers that hold the same data.  Writes are sent to a single server, the primary, from where it's asynchronously replicated to every secondary. You can control whether you allow reads to happen on secondaries or not, which can help direct some special queries away from the primary, at the risk of reading slightly stale data. If the primary goes down, one of the secondaries will be automatically elected to be the new primary. Again, MongoDB replication is outside the scope of this book.

## Sharding ##
MongoDB supports auto-sharding. Sharding is an approach to scalability which partitions your data across multiple servers or clusters. A naive implementation might put all of the data for users with a name that starts with A-M on server 1 and the rest on server 2. Thankfully, MongoDB's sharding capabilities far exceed such a simple algorithm. Sharding is a topic well beyond the scope of this book, but you should know that it exists and that you should consider it, should your needs grow beyond a single replica set.

While replication can help performance somewhat (by isolating long running queries to secondaries, and reducing latency for some other types of queries), its main purpose is to provide high availability. Sharding is the primary method for scaling MongoDB clusters. Combining replication with sharding is the perscribed approach to achieve scaling and high availability.

## Stats ##
You can obtain statistics on a database by typing `db.stats()`. Most of the information deals with the size of your database. You can also get statistics on a collection, say `unicorns`, by typing `db.unicorns.stats()`. Most of this information relates to the size of your collection and its indexes.

## Profiler ##
You enable the MongoDB profiler by executing:

	db.setProfilingLevel(2);

With it enabled, we can run a command:

	db.unicorns.find({weight: {$gt: 600}});

And then examine the profiler:

	db.system.profile.find()

The output tells us what was run and when, how many documents were scanned, and how much data was returned.

You disable the profiler by calling `setProfilingLevel` again but changing the parameter to `0`. Specifying `1` as the first parameter will profile queries that take more than 100 milliseconds. 100 milliseconds is the default threshold, you can specify a different minimum time, in milliseconds, with a second parameter:

	//profile anything that takes
	//more than 1 second
	db.setProfilingLevel(1, 1000);

## Backups and Restore ##
Within the MongoDB `bin` folder is a `mongodump` executable. Simply executing `mongodump` will connect to localhost and backup all of your databases to a `dump` subfolder. You can type `mongodump --help` to see additional options. Common options are `--db DBNAME` to back up a specific database and `--collection COLLECTIONNAME` to back up a specific collection. You can then use the `mongorestore` executable, located in the same `bin` folder, to restore a previously made backup. Again, the `--db` and `--collection` can be specified to restore a specific database and/or collection.  `mongodump` and `mongorestore` operate on BSON, which is MongoDB's native format.

For example, to back up our `learn` database to a `backup` folder, we'd execute (this is its own executable which you run in a command/terminal window, not within the mongo shell itself):

	mongodump --db learn --out backup

To restore only the `unicorns` collection, we could then do:

	mongorestore --db learn --collection unicorns \
		backup/learn/unicorns.bson

It's worth pointing out that `mongoexport` and `mongoimport` are two other executables which can be used to export and import data from JSON or CSV. For example, we can get a JSON output by doing:

	mongoexport --db learn --collection unicorns

And a CSV output by doing:

	mongoexport --db learn \
		--collection unicorns \
		--csv --fields name,weight,vampires

Note that `mongoexport` and `mongoimport` cannot always represent your data. Only `mongodump` and `mongorestore` should ever be used for actual backups.  You can read more about [your backup options](http://docs.mongodb.org/manual/core/backups/) in the MongoDB Manual.

## In This Chapter ##
In this chapter we looked at various commands, tools and performance details of using MongoDB. We haven't touched on everything, but we've looked at some of the common ones. Indexing in MongoDB is similar to indexing with relational databases, as are many of the tools. However, with MongoDB, many of these are to the point and simple to use.

# Conclusion #
You should have enough information to start using MongoDB in a real project. There's more to MongoDB than what we've covered, but your next priority should be putting together what we've learned, and getting familiar with the driver you'll be using. The [MongoDB website](http://www.mongodb.org/) has a lot of useful information. The official [MongoDB user group](http://groups.google.com/group/mongodb-user) is a great place to ask questions.

NoSQL was born not only out of necessity, but also out of an interest in trying new approaches. It is an acknowledgment that our field is ever-advancing and that if we don't try, and sometimes fail, we can never succeed. This, I think, is a good way to lead our professional lives.
